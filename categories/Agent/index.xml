<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Agent on Vision</title>
    <link>https://www6v.github.io/www6vVision/categories/Agent/</link>
    <description>Recent content in Agent on Vision</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Fri, 30 Jun 2023 21:12:35 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vVision/categories/Agent/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Agent - UI-assistants</title>
      <link>https://www6v.github.io/www6vVision/docs/%E5%A4%9A%E6%A8%A1%E6%80%81-Agent/MultimodalAgentApp/</link>
      <pubDate>Fri, 30 Jun 2023 21:12:35 +0000</pubDate>
      <guid>https://www6v.github.io/www6vVision/docs/%E5%A4%9A%E6%A8%A1%E6%80%81-Agent/MultimodalAgentApp/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;参考&#34;&gt;&#xA;  参考&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;app-agent&#34;&gt;&#xA;  App Agent&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#app-agent&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;1xx. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/677071947&#34;&gt;AppAgent源码分析&amp;amp;思考&lt;/a&gt;&#xA;&lt;a href=&#34;https://github.com/mnotgod96/AppAgent&#34;&gt;https://github.com/mnotgod96/AppAgent&lt;/a&gt;&#xA;&lt;a href=&#34;https://icoz69.github.io/&#34;&gt;https://icoz69.github.io/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;1xx. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/681424409&#34;&gt;【LLM-agent】MOBILE-AGENT: 具有视觉感知能力的自治多模移动设备agent&lt;/a&gt;&#xA;&lt;a href=&#34;https://github.com/X-PLUG/MobileAgent&#34;&gt;https://github.com/X-PLUG/MobileAgent&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;1xx. &lt;a href=&#34;https://github.com/OpenAdaptAI/OpenAdapt&#34;&gt;https://github.com/OpenAdaptAI/OpenAdapt&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)Web Agent</title>
      <link>https://www6v.github.io/www6vVision/docs/%E5%A4%9A%E6%A8%A1%E6%80%81-Agent/WebAgent/</link>
      <pubDate>Sun, 05 Mar 2023 10:30:03 +0000</pubDate>
      <guid>https://www6v.github.io/www6vVision/docs/%E5%A4%9A%E6%A8%A1%E6%80%81-Agent/WebAgent/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;web-scenarios-1&#34;&gt;&#xA;  web scenarios [1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#web-scenarios-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;在网络场景中，代表用户执行特定任务被称为Web导航问题[390]。代理程序解释用户指令，将其分解为多个基本操作，并与计算机进行交互。这通常涉及到填写表单、在线购物和发送电子邮件等网络任务。代理程序需要具备理解复杂网络场景中的指令的能力，适应变化（如嘈杂的文本和动态HTML网页），并推广成功的操作[391]。通过这种方式，代理程序可以在处理未知任务时实现可访问性和自动化[435]，最终使人类免于与计算机用户界面的重复交互。&lt;/p&gt;&#xA;&lt;p&gt;通过强化学习训练的代理程序可以有效地模仿人类行为，使用预定义的操作，如键入、搜索、导航到下一页等。它们在基本任务（如在线购物[392]和搜索引擎检索[90]）中表现良好，这些任务已经得到广泛探索。然而，没有语言模型能力的代理程序可能难以适应现实世界互联网中更真实和复杂的场景。在动态、内容丰富的网页上，如在线论坛或在线业务管理[391]，代理程序常常面临性能方面的挑战。&lt;/p&gt;&#xA;&lt;p&gt;为了实现代理程序与更真实的网页之间的成功交互，一些研究人员[393；394]开始利用语言模型的强大HTML读取和理解能力。通过设计提示，他们试图使代理程序理解整个HTML源代码，并预测更合理的下一步操作。Mind2Web[389]结合了为HTML进行微调的多个语言模型，使它们能够在现实世界的场景中总结冗长的HTML代码[388]并提取有价值的信息。此外，WebGum[390]通过使用包含HTML截屏的多模态语料库，赋予代理程序视觉感知能力。它同时进行了语言模型和视觉编码器的微调，加深了代理程序对网页的全面理解。&lt;/p&gt;&#xA;&lt;p&gt;Performing specific tasks on behalf of users in a web scenario is known as the web navigation problem [390]. Agents interpret user instructions, break them down into multiple basic operations, and interact with computers. This often includes web tasks such as filling out forms, online shopping, and sending emails. Agents need to possess the ability to understand instructions within complex web scenarios, adapt to changes (such as noisy text and dynamic HTML web pages), and generalize successful operations [391]. In this way, agents can achieve accessibility and automation when dealing with unseen tasks in the future [435], ultimately freeing humans from repeated interactions with computer UIs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)Agent 多模态</title>
      <link>https://www6v.github.io/www6vVision/docs/%E5%A4%9A%E6%A8%A1%E6%80%81-Agent/MultimodalAgent/</link>
      <pubDate>Tue, 21 Feb 2023 10:10:51 +0000</pubDate>
      <guid>https://www6v.github.io/www6vVision/docs/%E5%A4%9A%E6%A8%A1%E6%80%81-Agent/MultimodalAgent/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h2 id=&#34;目录&#34;&gt;&#xA;  目录&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e7%9b%ae%e5%bd%95&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;!-- toc --&gt;&#xA;&lt;h1 id=&#34;论文&#34;&gt;&#xA;  论文&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e8%ae%ba%e6%96%87&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;论文地址&#xA;&lt;a href=&#34;https://arxiv.org/abs/2402.15116&#34;&gt;《Large Multimodal Agents: A Survey》&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;开源地址&#xA;&lt;a href=&#34;https://github.com/jun0wanan/awesome-large-multimodal-agents&#34;&gt;Repo&lt;/a&gt; git&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;survey&#34;&gt;&#xA;  Survey&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#survey&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;类型-i无长期记忆的闭源-llms-作为规划器&#34;&gt;&#xA;  类型 I：无长期记忆的闭源 LLMs 作为规划器。&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e7%b1%bb%e5%9e%8b-i%e6%97%a0%e9%95%bf%e6%9c%9f%e8%ae%b0%e5%bf%86%e7%9a%84%e9%97%ad%e6%ba%90-llms-%e4%bd%9c%e4%b8%ba%e8%a7%84%e5%88%92%e5%99%a8&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2303.04671.pdf&#34;&gt;&lt;strong&gt;Visual ChatGPT&lt;/strong&gt;&lt;/a&gt;  ***&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2303.11381.pdf&#34;&gt;&lt;strong&gt;MM-REACT&lt;/strong&gt;&lt;/a&gt;  ***&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2303.08128.pdf&#34;&gt;&lt;strong&gt;ViperGPT&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2303.17580.pdf&#34;&gt;&lt;strong&gt;HuggingGPT&lt;/strong&gt;&lt;/a&gt;  ***&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2304.09842.pdf&#34;&gt;&lt;strong&gt;Chameleon&lt;/strong&gt;&lt;/a&gt; ***&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2311.00571.pdf&#34;&gt;&lt;strong&gt;LLaVA-Interactive&lt;/strong&gt;&lt;/a&gt; ***&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2401.01614&#34;&gt;&lt;strong&gt;SeeAct&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2310.01415.pdf&#34;&gt;&lt;strong&gt;GPT-Driver&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2401.16158.pdf&#34;&gt;&lt;strong&gt;Mobile-Agent&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;类型-ii无长期记忆的微调-llms-作为规划器&#34;&gt;&#xA;  类型 II：无长期记忆的微调 LLMs 作为规划器。&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e7%b1%bb%e5%9e%8b-ii%e6%97%a0%e9%95%bf%e6%9c%9f%e8%ae%b0%e5%bf%86%e7%9a%84%e5%be%ae%e8%b0%83-llms-%e4%bd%9c%e4%b8%ba%e8%a7%84%e5%88%92%e5%99%a8&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2306.08640.pdf&#34;&gt;&lt;strong&gt;LLaVA-Plus&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2305.18752.pdf&#34;&gt;&lt;strong&gt;GPT4Tools&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;类型-iv具有本地长期记忆的规划器&#34;&gt;&#xA;  类型 IV：具有本地长期记忆的规划器。&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e7%b1%bb%e5%9e%8b-iv%e5%85%b7%e6%9c%89%e6%9c%ac%e5%9c%b0%e9%95%bf%e6%9c%9f%e8%ae%b0%e5%bf%86%e7%9a%84%e8%a7%84%e5%88%92%e5%99%a8&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2311.05997.pdf&#34;&gt;&lt;strong&gt;JARV IS-1&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2312.13771.pdf&#34;&gt;&lt;strong&gt;AppAgent&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2307.07162.pdf&#34;&gt;&lt;strong&gt;DLAH&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;多模态-agent1&#34;&gt;&#xA;  多模态 Agent[1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%a4%9a%e6%a8%a1%e6%80%81-agent1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;核心组件&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;感知&lt;/strong&gt;组件关注处理多模态信息&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;规划器&lt;/strong&gt;负责推理和制定计划&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;行动&lt;/strong&gt;组件执行计划&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;记忆&lt;/strong&gt;组件则涉及长期和短期记忆&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;四种类型&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;无长期记忆的闭源 LLMs 作为规划器&lt;/li&gt;&#xA;&lt;li&gt;无长期记忆的微调 LLMs 作为规划器&lt;/li&gt;&#xA;&lt;li&gt;具有间接长期记忆的规划器&lt;/li&gt;&#xA;&lt;li&gt;具有本地长期记忆的规划器&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;多智能体协作&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
