<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vision</title>
    <link>https://www6v.github.io/www6vVision/tags/Vision/</link>
    <description>Recent content on Vision</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Tue, 25 Jul 2023 13:49:28 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vVision/tags/Vision/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CV 任务</title>
      <link>https://www6v.github.io/www6vVision/docs/Vision/VisionTask/</link>
      <pubDate>Tue, 25 Jul 2023 13:49:28 +0000</pubDate>
      <guid>https://www6v.github.io/www6vVision/docs/Vision/VisionTask/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;分类-1&#34;&gt;&#xA;  分类 [1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%88%86%e7%b1%bb-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;image-level&#34;&gt;&#xA;  image-level&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#image-level&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;image recognition&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;(Retrieval)image-text retrieval&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Caption(image captioning)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;VQA(visual question answering)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;region-level&#34;&gt;&#xA;  region-level&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#region-level&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Object Detection object detection&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;DETR -&amp;gt; DINO -&amp;gt; Grounding DINO&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;dense caption&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;phrase grounding&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;pixel-level&#34;&gt;&#xA;  pixel-level&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#pixel-level&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Segmentation&#xA;&lt;ul&gt;&#xA;&lt;li&gt;generic segmetation&lt;/li&gt;&#xA;&lt;li&gt;referring segmetation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;其他&#34;&gt;&#xA;  其他&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%85%b6%e4%bb%96&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;对比&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;[CNN  更深的网络]&lt;/li&gt;&#xA;&lt;li&gt;[transformer 没有局限]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;CV任务&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;分类（Classification）&lt;/li&gt;&#xA;&lt;li&gt;检测（Detection）&lt;/li&gt;&#xA;&lt;li&gt;分割（Segmentation）&lt;/li&gt;&#xA;&lt;li&gt;跟踪（Tracking）&lt;/li&gt;&#xA;&lt;li&gt;行为识别（Action Recognition）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;参考&#34;&gt;&#xA;  参考&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;[&lt;a href=&#34;https://www.bilibili.com/video/BV1ds4y1k7pj/?vd_source=f6e8c1128f9f264c5ab8d9411a644036&#34;&gt;CVPR Tutorial Talk] Towards General Vision Understanding Interface&lt;/a&gt;&#xA;&lt;a href=&#34;https://datarelease.blob.core.windows.net/tutorial/vision_foundation_models_2023/slides/Jianwei_CVPR2023_Tutorial.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
  </channel>
</rss>
